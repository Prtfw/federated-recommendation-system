{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import syft as sy\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovieLense DataSet Input\n",
    "\n",
    "rs_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "user_ratings_base = pd.read_csv('Data/ua.base', sep='\\t', names=rs_cols, encoding='latin-1')\n",
    "user_ratings_test = pd.read_csv('Data/ua.test', sep='\\t', names=rs_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9430.000000</td>\n",
       "      <td>9430.000000</td>\n",
       "      <td>9430.000000</td>\n",
       "      <td>9.430000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>400.800954</td>\n",
       "      <td>3.587805</td>\n",
       "      <td>8.837354e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>272.234934</td>\n",
       "      <td>306.859789</td>\n",
       "      <td>1.120240</td>\n",
       "      <td>5.360562e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.747247e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>236.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.794515e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.833904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>708.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.886378e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>1664.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.932866e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id     movie_id       rating  unix_timestamp\n",
       "count  9430.000000  9430.000000  9430.000000    9.430000e+03\n",
       "mean    472.000000   400.800954     3.587805    8.837354e+08\n",
       "std     272.234934   306.859789     1.120240    5.360562e+06\n",
       "min       1.000000     1.000000     1.000000    8.747247e+08\n",
       "25%     236.000000   182.000000     3.000000    8.794515e+08\n",
       "50%     472.000000   303.000000     4.000000    8.833904e+08\n",
       "75%     708.000000   566.000000     4.000000    8.886378e+08\n",
       "max     943.000000  1664.000000     5.000000    8.932866e+08"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create user-item matrix\n",
    "\n",
    "n_users_base = user_ratings_base['user_id'].unique().max()\n",
    "n_items_base = user_ratings_base['movie_id'].unique().max()\n",
    "\n",
    "train_matrix = np.zeros((n_users_base, n_items_base))\n",
    "for line in user_ratings_base.itertuples():\n",
    "    train_matrix[line[1]-1,line[2]-1] = line[3]\n",
    "\n",
    "    \n",
    "n_users_test = user_ratings_test['user_id'].unique().max()\n",
    "n_items_test = user_ratings_test['movie_id'].unique().max()\n",
    "\n",
    "test_matrix = np.zeros((n_users_base, n_items_base))\n",
    "for line in user_ratings_test.itertuples():\n",
    "    test_matrix[line[1]-1,line[2]-1] = line[3]    \n",
    "\n",
    "movies_ids = torch.tensor(list(range(1,n_items_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create virtual workers\n",
    "\n",
    "workers_nodes = []\n",
    "\n",
    "#training\n",
    "workers_train_data_pointers = []\n",
    "\n",
    "for idx, train_ratings in enumerate(train_matrix):\n",
    "    worker = sy.VirtualWorker(hook, id=\"user_\"+str(idx))\n",
    "    data_pointer = sy.BaseDataset(movies_ids, torch.tensor(train_ratings)).send(worker)\n",
    "    workers_nodes.append(worker)\n",
    "    workers_train_data_pointers.append(data_pointer)\n",
    "\n",
    "    \n",
    "#testing\n",
    "workers_test_data_pointers = []\n",
    "\n",
    "for idx, test_ratings in enumerate(test_matrix):\n",
    "    data_pointer = sy.BaseDataset(movies_ids, torch.tensor(test_ratings)).send(workers_nodes[idx])\n",
    "    workers_test_data_pointers.append(data_pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create federated training datasets\n",
    "federated_train_dataset = sy.FederatedDataset(workers_train_data_pointers)\n",
    "# Create federated training dataloaders\n",
    "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create federated testing datasets\n",
    "federated_test_dataset = sy.FederatedDataset(workers_test_data_pointers)\n",
    "# Create federated testing dataloaders\n",
    "federated_test_loader = sy.FederatedDataLoader(federated_test_dataset, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(federated_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (item_embedding): Embedding(1682, 50)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=50, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # item embedding layers\n",
    "        embedding_dim = 50\n",
    "        self.item_embedding = nn.Embedding(n_items_base, embedding_dim)\n",
    "        \n",
    "        # list of weight matrices\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        self.fc_layers.append(nn.Linear(50, 50))\n",
    "        # final prediction layer\n",
    "        self.output_layer = nn.Linear(50, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.item_embedding(movies_ids)\n",
    "        \n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.dropout(x, p=0.2)\n",
    "            x = F.batch_norm(x)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        logit = self.output_layer(x)\n",
    "        rating = torch.sigmoid(logit)\n",
    "        return rating\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "\n",
    "def testing():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in federated_test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(federated_test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss,\n",
    "        correct,\n",
    "        len(federated_test_loader),\n",
    "        100. * correct / len(federated_test_loader)))\n",
    "\n",
    "def training(is_global, epoch_count):\n",
    "    for epoch in range(0, epoch_count):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
    "            # NEW) send model to correct worker\n",
    "            model.send(data.location)\n",
    "            \n",
    "            #Call the optimizer for the worker using get_optim\n",
    "            opt = optims.get_optim(data.location.id)\n",
    "            #print(data.location.id)\n",
    "\n",
    "            # 1) erase previous gradients (if they exist)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # 2) make a prediction\n",
    "            pred = model(data)\n",
    "\n",
    "            # 3) calculate how much we missed\n",
    "            loss = ((pred - target)**2).sum()\n",
    "\n",
    "            # 4) figure out which weights caused us to miss\n",
    "            loss.backward()\n",
    "\n",
    "            # 5) change those weights\n",
    "            opt.step()\n",
    "            \n",
    "            # NEW) get model (with gradients)\n",
    "            model.get()\n",
    "\n",
    "            # 6) print our progress\n",
    "            print(loss.get()) # NEW) slight edit... need to call .get() on loss\\\n",
    "    \n",
    "def learning_algo():\n",
    "    #Algorithm for training in Federated way\n",
    "    for cycle in range(0,10):\n",
    "        # global training\n",
    "        training(True, 10)\n",
    "        \n",
    "        #local training\n",
    "        training(False, 100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
